---
author: [Preston Smith, Vital Joseph, Gregory M. Kapfhammer]
title: Statistical Debugging
date: '2023-12-12'
date-format: long
categories: [post, software engineering, debugging book]
description: <em>How can we use statistical debugging find bugs?</em>
toc: true
page-layout: full
---

## Overview

This article covers the ["Statistical
Debugging"](https://www.debuggingbook.org/html/StatisticalDebugger.html) chapter
from [The Debugging Book](https://www.debuggingbook.org/). In this article we
will summarize the chapter and discuss how its content could be utilized within
the context of the implementation and testing of the
[Chasten](https://github.com/AstuteSource/chasten) and
[Cellveyor](https://github.com/GatorEducator/cellveyor) tools.

## Summary

Statistical Debugging is a method used to troubleshoot programs that exhibit
both passing and failing behavior depending on the inputs they receive. The
primary objective is to establish a connection between program failure(s) and
specific part(s) of the code, whether it's a single line or multiple lines. The
process starts with a **collector**, a class responsible for gathering
information about each line of the program's execution.

The provided example introduces a simple collector class from the ["Debugging
Book"](https://www.debuggingbook.org/html/StatisticalDebugger.html), named
**Collector**, which records events during execution. This class can be extended
and customized for specific needs.

```python
class Collector(Tracer):
    """A class to record events during execution."""

    def collect(self, frame: FrameType, event: str, arg: Any) -> None:
        """Collecting function. To be overridden in subclasses."""
        pass

    def events(self) -> Set:
        """Return a collection of events. To be overridden in subclasses."""
        return set()

    def traceit(self, frame: FrameType, event: str, arg: Any) -> None:
        self.collect(frame, event, arg)
```

After running the program multiple times, the lines of code are then ranked by
**suspiciousness**. This metric determines the likelihood of a line causing a
program failure. The ranking is established by analyzing which parts of the code
were ran during failing runs and comparing them to successful runs.

A key part of the process is knowing what is being run through tracking the
**Code Coverage**. The below subclass from the ["Debugging
Book"](https://www.debuggingbook.org/html/StatisticalDebugger.html) is used to
track which lines are being run an returns a set of tuples with the function
names and the lines ran. This allows the collector keep track of what is being
run in a formatted way to be used later.

```python
class CoverageCollector(Collector, StackInspector):
    """A class to record covered locations during execution."""

    def __init__(self) -> None:
        """Constructor."""
        super().__init__()
        self._coverage: Coverage = set()

    def collect(self, frame: FrameType, event: str, arg: Any) -> None:
        """
        Save coverage for an observed event.
        """
        name = frame.f_code.co_name
        function = self.search_func(name, frame)

        if function is None:
            function = self.create_function(frame)

        location = (function, frame.f_lineno)
        self._coverage.add(location)
class CoverageCollector(CoverageCollector):
    def events(self) -> Set[Tuple[str, int]]:
        """
        Return the set of locations covered.
        Each location comes as a pair (`function_name`, `lineno`).
        """
        return {(func.__name__, lineno) for func, lineno in self._coverage}
```

The ultimate goal is to find a connection between failing and passing runs and
specific parts of the code. This involves splitting the collected information
based on whether the outcome was a `PASS` or `FAIL`. The following code snippet
exemplifies this process:

```python
class StatisticalDebugger(StatisticalDebugger):
    def collect(self, outcome: str, *args: Any, **kwargs: Any) -> Collector:
        """Return a collector for the given outcome. 
        Additional args are passed to the collector."""
        collector = self.collector_class(*args, **kwargs)
        collector.add_items_to_ignore([self.__class__])
        return self.add_collector(outcome, collector)

    def add_collector(self, outcome: str, collector: Collector) -> Collector:
        if outcome not in self.collectors:
            self.collectors[outcome] = []
        self.collectors[outcome].append(collector)
        return collector
```

After being grouped the results are then ready to be analyzed and ranked. Making
this a multi-step process that can be complicated and requires a significant
amount of computation to achieve. Despite that, statistical debugging provides
crucial insights into how a program fails over time, aiding in the
identification of root causes. The ability to analyze a codebase being
especially valuable, especially in enhancing the debugging process for large
projects where efficiency is essential.

## Reflection

Statistical debugging is a powerful method for troubleshooting programs with
failures. Its key objective is to establish a connection between program
failures and specific parts of the code. The process involves collecting data
during program execution, ranking lines of code by failure possibility, and
analyzing the differences between passing and failing runs.

The provided code snippets illustrate a basic framework for statistical
debugging, using a Collector class to gather information during execution. This
class can be extended and customized to suit specific debugging needs.

The concept of code coverage plays a crucial role in statistical debugging. The
`CoverageCollector` subclass is introduced to track which lines of code are
executed and returns a formatted set of tuples with function names and
corresponding line numbers. This coverage information is essential for
understanding what parts of the code are contributing to program failures.

The `StatisticalDebugger` class is then presented as a way to organize and
analyze the collected data. It uses different collectors for passing and failing
outcomes and facilitates the grouping of results for further analysis. This
multi-step process involves significant computation but provides insights into
the behavior of the program over multiple runs.

In summary, statistical debugging is a complex approach that requires careful
instrumentation of code and analysis of collected data. Despite its
computational complexity, it offers valuable benefits, especially in large
projects where efficiently identifying and resolving bugs is crucial. The
ability to analyze a codebase over multiple runs provides developers with a
deeper understanding of the program's behavior, ultimately aiding in the
identification of root causes for intermittent failures.

## Action Items

Statistical debugging is like having a special tool to find and fix mistakes in
big and complicated computer programs. Imagine if you had a really huge puzzle,
and instead of looking at each piece one by one, you use a smart method to see
which pieces are most likely to be part of a problem. Statistical debugging does
something similar for computer programs. It helps developers understand how the
program behaves and where mistakes might be hiding. This way, they can find and
fix the issues faster, especially when dealing with large and complex code. Our
development teams could incorporate this technique for debugging, but ultimately
would have to decide as a team if implementing this type of technique would be
necessary for our tools chasten and cellveyor specifically. It might prove to be
more beneficial in the future though, as our code becomes more and more complex.

<!-- Include the license statement for the online book -->
{{< include /_debuggingbook-reference.qmd >}}

<!-- Include reference back to the listing of blog posts -->
{{< include /_back-blog.qmd >}}
